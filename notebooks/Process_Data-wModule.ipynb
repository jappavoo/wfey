{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "9f01d331-19df-4bb4-8e33-3e5dcb1b80f4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Home Directory = /home/cjpar/Work/wfe/wfey\n",
      "Log Path = /home/cjpar/Work/wfe/wfey/logs/zero_test/\n"
     ]
    }
   ],
   "source": [
    "%run SetUp.ipynb"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00741e39-f383-4d4e-95ef-4cfadd38a100",
   "metadata": {},
   "source": [
    "# Processing Logs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "003dbb37-3d39-4f1a-8720-707bcf465370",
   "metadata": {},
   "outputs": [],
   "source": [
    "def removeOutliers(DATA, THRESHHOLD_Z=2, VERBOSE=False):\n",
    "    \n",
    "    hwmon2_mean_z  = np.abs(stats.zscore(DATA['hwmon2_mean'], nan_policy='omit'))\n",
    "    hwmon2_min_z   = np.abs(stats.zscore(DATA['hwmon2_min'], nan_policy='omit'))\n",
    "    hwmon2_max_z   = np.abs(stats.zscore(DATA['hwmon2_max'], nan_policy='omit'))\n",
    "    latency_mean_z = np.abs(stats.zscore(DATA['latency_mean'], nan_policy='omit'))\n",
    "    latency_min_z  = np.abs(stats.zscore(DATA['latency_min'], nan_policy='omit'))\n",
    "    latency_max_z  = np.abs(stats.zscore(DATA['latency_max'], nan_policy='omit'))\n",
    "\n",
    "    hwmon2_mean_out = np.where(hwmon2_mean_z > THRESHHOLD_Z)[0]\n",
    "    hwmon2_min_out = np.where(hwmon2_min_z > THRESHHOLD_Z)[0]\n",
    "    hwmon2_max_out = np.where(hwmon2_max_z > THRESHHOLD_Z)[0]\n",
    "    latency_mean_out = np.where(latency_mean_z > THRESHHOLD_Z)[0]\n",
    "    latency_min_out = np.where(latency_min_z > THRESHHOLD_Z)[0]\n",
    "    latency_max_out = np.where(latency_max_z > THRESHHOLD_Z)[0]\n",
    "\n",
    "    \n",
    "    outlier_indices = np.unique(np.concat((hwmon2_mean_out, hwmon2_min_out, hwmon2_max_out, latency_mean_out, latency_min_out, latency_max_out)))\n",
    "    no_outliers = DATA.drop(outlier_indices)\n",
    "\n",
    "    if (VERBOSE):\n",
    "        print(\"Z scores:\")\n",
    "        print(\"Hwmon2 mean, min, max\")\n",
    "        print(hwmon2_mean_z, hwmon2_min_z, hwmon2_max_z)\n",
    "        print(\"Latency mean, min, max\")\n",
    "        print(latency_mean_z,latency_min_z,latency_max_z)\n",
    "        \n",
    "        print(\"Original DataFrame Shape:\", DATA.shape)\n",
    "        print(\"DataFrame Shape after Removing Outliers:\", no_outliers.shape)\n",
    "        print(\"Removed Indexes:\")\n",
    "        print(outlier_indices)\n",
    "        print(\"\\t HWMON -- mean, min, max\")\n",
    "        print(DATA.loc[hwmon2_mean_out, ['KEY', 'hwmon2_mean']])\n",
    "        print(DATA.loc[hwmon2_min_out, ['KEY', 'hwmon2_min']])\n",
    "        print(DATA.loc[hwmon2_max_out, ['KEY', 'hwmon2_max']])\n",
    "        print(\"\\t Latency -- mean, min, max\")\n",
    "        print(DATA.loc[latency_mean_out, ['KEY', 'latency_mean']])\n",
    "        print(DATA.loc[latency_min_out, ['KEY', 'latency_min']])\n",
    "        print(DATA.loc[latency_max_out, ['KEY', 'latency_max']])\n",
    "    \n",
    "    return no_outliers.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "9a128674-f21d-45ed-8e0b-da4245fac306",
   "metadata": {},
   "outputs": [],
   "source": [
    "arr = []\n",
    "data = []\n",
    "\n",
    "# If RAW=True this means that the entire run's hwmon data will be used, if false only the middle 68% will be used\n",
    "\n",
    "def processData(CONFIGS, EVENTRATE, EVENTPROCCPUS, SOURCESCPUS, RAW=True, VERBOSE=False):\n",
    "    column_headers = []\n",
    "    for C in CONFIGS:\n",
    "        for EVENTS in EVENTRATE:\n",
    "            for EVENTCPU in EVENTPROCCPUS:\n",
    "                for SOURCECPU in SOURCECPUS:\n",
    "                    SCPUs=str(SOURCECPU).replace(\" \", \"_\")\n",
    "\n",
    "                    KEY=C+\"/\"+str(EVENTS)+\"_\"+EVENTCPU+\"_\"+SCPUs\n",
    "                    FILE=PATH_TO_LOGS+KEY+\"/\"\n",
    "                    HWMONFILE=glob.glob(FILE+'hwmon-*.out')\n",
    "\n",
    "                    # If no files found with these args -- skip\n",
    "                    if not HWMONFILE:\n",
    "                        continue\n",
    "                        \n",
    "                    ### For every run of this set of parameters concat\n",
    "                    hwmonoutput=None\n",
    "                    latencyoutput=None\n",
    "                    bmoutput=None\n",
    "\n",
    "                    if VERBOSE:\n",
    "                        print(\"KEY: \", KEY)\n",
    "\n",
    "                    for runs in HWMONFILE:\n",
    "                        hw_file = runs\n",
    "                        bm_file = runs.replace(\"hwmon\", \"wfey\")\n",
    "                        latency_file = runs.replace(\"hwmon\", \"latency\")\n",
    "                           \n",
    "                        if (os.path.exists(hw_file)) and (os.path.exists(bm_file)) and (os.path.exists(latency_file)):\n",
    "                            ## --- Grabbing Energy Numbers --- ##\n",
    "                            if VERBOSE:\n",
    "                                print(\"processsing:\" + hw_file)\n",
    "                                \n",
    "                            try:\n",
    "                                df=pd.read_csv(hw_file, sep=' ')\n",
    "                                df = df.iloc[:, :-1] # dropping last column because there is an extra space to be dealt with later\n",
    "                                ## NOTE: if we want min/max numbers this needs to be done later and the start and end values should stay\n",
    "                                df = df.diff().iloc[1:2, :]\n",
    "                            except:\n",
    "                                print(\"SKIPPING: \" + hw_file + \" --- Problem parsing hwmon numbers\")\n",
    "                                continue\n",
    "\n",
    "                            if (len(df) > OVERFLOW_NUM):\n",
    "                                print(\"SKIPPING: \" + hw_file  +\" --- Possible error occured during experiment\")\n",
    "                                continue\n",
    "                            \n",
    "                            \n",
    "\n",
    "                            ### This fix was for old version with know headers -- we will see if this is an issue that needs to be dealt in this version as well\n",
    "                            ### I hypothesize that the 'none' check of the outputs below check for the same bug and that is sufficient\n",
    "                            ## KNOWN BUG: if no header on cvs and error with gathering HWMON it will not catch it and create table of NULL\n",
    "                            #if (list(hwmonoutput) != ['hwmon2', 'hwmon3']):\n",
    "                            #    print(\"bad columns for:\", runs)\n",
    "\n",
    "                            ## --- Grabbing Benchmark Numbers --- ##\n",
    "                            if VERBOSE:\n",
    "                                print(\"processsing:\" + bm_file)\n",
    "\n",
    "                            try:\n",
    "                                wfey_file_contents=[]\n",
    "                                with open(bm_file) as wfey_file:\n",
    "                                    wfey_file_contents = [line.strip() for line in wfey_file]\n",
    "                                    wfey_file.close()\n",
    "\n",
    "                                ### TODO - combine the next two lists into one\n",
    "                                bm_string_list = [dict([kv.split('=') for kv in record.split(', ')]) for record in wfey_file_contents]\n",
    "                                ### NOTE: address value of epthread convers into a int -- useless\n",
    "                                bm_list = [dict([a, int(x,0)] for a, x in b.items()) for b in bm_string_list]\n",
    "                                bm_df=pd.DataFrame(bm_list)\n",
    "                            except:\n",
    "                                print(\"SKIPPING: \" + bm_file + \" --- Problem parsing benchmark numbers\")\n",
    "                                continue\n",
    "\n",
    "                            ## --- Grabbing Latency Numbers --- ##\n",
    "                            if VERBOSE:\n",
    "                                print(\"processsing:\" + latency_file)\n",
    "\n",
    "                            try:\n",
    "                                latency_df = pd.read_csv(latency_file)\n",
    "                            except:\n",
    "                                print(\"SKIPPING: \" + latency_file + \" --- Problem parsing latency numbers\")\n",
    "                                continue\n",
    "\n",
    "                            ## --- Adding all Values of this File to Output --- ##\n",
    "\n",
    "                            hwmonoutput = pd.concat([hwmonoutput, df])\n",
    "                            bmoutput = pd.concat([bmoutput, bm_df])\n",
    "                            latencyoutput = pd.concat([latencyoutput, latency_df])\n",
    "                        else:\n",
    "                            files = runs.replace(\"hwmon\", \"*\")\n",
    "                            print(\"SKIPPING: \" + files + \" --- Problem with Test Output\")\n",
    "                            continue\n",
    "\n",
    "                   \n",
    "                    if (hwmonoutput is None) or (latencyoutput is None) or (bmoutput is None):\n",
    "                        continue\n",
    "\n",
    "\n",
    "                    #print(\"hwmon output: \", hwmonoutput)\n",
    "                    #print(\"latency output: \", latencyoutput)\n",
    "                    #print(\"bm output: \", bmoutput)\n",
    "                    \n",
    "                    ## --- Find the energy mean of all runs --- ##\n",
    "                    by_row_index = hwmonoutput.groupby(hwmonoutput.index)\n",
    "                    raw_result=by_row_index.mean()\n",
    "                    \n",
    "                    ## --- Find the bm mean of all runs --- ##\n",
    "                    ### TODO add not raw output to the benchmark data\n",
    "                    bm_by_row_index = bmoutput.groupby(bmoutput.index)\n",
    "                    bm_raw_result=bm_by_row_index.mean()\n",
    "\n",
    "                    ## --- Raw Data or Middle Data --- ##\n",
    "                    results = raw_result\n",
    "                    bm_results = bm_raw_result\n",
    "                    if (not RAW):\n",
    "                        adj_index = round(len(raw_result)*(PERCENT/100))\n",
    "\n",
    "                        middle_point = round(len(raw_result)/2)\n",
    "\n",
    "                        low_index = middle_point-(math.floor(adj_index/2))\n",
    "                        high_index = middle_point + (math.floor(adj_index/2))\n",
    "\n",
    "                        results = raw_result[low_index : high_index+1]\n",
    " \n",
    "                    ## --- Find Means of Latencys --- ###\n",
    "                    ### This means that the individual data for the sources is not saved \n",
    "                    ### But I believe that's fine bc we don't care about the about the data\n",
    "                    ### at the cpu scale but the number of cpu handling the workload\n",
    "                    \n",
    "                    latency_results=latencyoutput.drop(\"ID\", axis=1)\n",
    "\n",
    "                    \n",
    "                    latency_min = latency_results.loc[:,\"Min\"].to_numpy()\n",
    "                    latency_max = latency_results.loc[:,\"Max\"].to_numpy()\n",
    "\n",
    "                    latency_min = stats.gmean(latency_min)\n",
    "                    latency_max = stats.gmean(latency_max)\n",
    "\n",
    "                    ### NOTE: If the sources had no completed events then the mean is -1\n",
    "                    ### You can use this as a landmark to skip those values when evaluating\n",
    "                    ### If mean is nan you know there were 0 events total\n",
    "                    latency_mean = latency_results.loc[:,\"Mean\"].to_numpy()\n",
    "                    latency_mean = [x for x in latency_mean if x!=-1]\n",
    "                    with warnings.catch_warnings(): \n",
    "                        # assuming nan mean is okay because means no events at all\n",
    "                        warnings.filterwarnings(action=\"ignore\", message='One or more sample arguments is too small')\n",
    "                        latency_mean = stats.gmean(latency_mean)\n",
    "\n",
    "                    \n",
    "                    ## --- Processing Output --- ##\n",
    "                    temp_headers = []\n",
    "                    ## --- Making array out of core output --- ##\n",
    "                    core_energy_data = []\n",
    "                    for core_name in results.columns:\n",
    "                        temp_headers.append(core_name)\n",
    "                        core_results = results.loc[:, core_name].to_numpy()\n",
    "                        core_energy_data.append(core_results[0]) # only grabbing the one result -- more are not expected?\n",
    "            \n",
    "                    ## --- Making array out of Benchmark output --- ##\n",
    "                    ### TODO -- sanity check this with multiple values because this was done quick and sloppy\n",
    "                    ### i.e don't want id to be mean'ed together\n",
    "                    bm_data = []\n",
    "                    for bm_data_name in bm_results.columns:\n",
    "                        temp_headers.append(bm_data_name)\n",
    "                        bm_data.append(bm_results.loc[:, bm_data_name].to_numpy())\n",
    "\n",
    "                    ### HACK that this is here -- want the headers used in the files and i'm taking the first one processed as truth\n",
    "                    ### if there is a bug in the file -- everything goes to shit but i believe above error checking makes here safe\n",
    "                    if not column_headers:\n",
    "                        column_headers = temp_headers\n",
    "                        \n",
    "                    ## --- Adding data to list --- ##\n",
    "                    \n",
    "                    main_values = [KEY,C,EVENTS,EVENTCPU,SCPUs, latency_min, latency_max, latency_mean]\n",
    "                    var_values = core_energy_data + bm_data\n",
    "\n",
    "                    all_values = main_values + var_values\n",
    "                    arr.append(all_values)\n",
    "\n",
    "    constant_headers = [ \"KEY\", \"configs\", \"eventrate\", \"eventprocCPUs\", \"sourceCPUs\", \"latency_min\", \"latency_max\", \"latency_mean\"]\n",
    "    all_headers = constant_headers + column_headers\n",
    "\n",
    "    df = pd.DataFrame(data=arr, columns=all_headers)    \n",
    "    #print(df)\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3aaf3751-0a3d-4978-9457-92f87e8f134f",
   "metadata": {},
   "source": [
    "### Creating Dataframes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5351f56-6543-47a4-acad-b3de35b4b741",
   "metadata": {},
   "source": [
    "##### Process the Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "fdf45a64-b59d-46b6-b20f-57c2b1539f1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "wfey_output = processData(CONFIGS, EVENTRATE, EVENTPROCCPUS, SOURCECPUS, RAW=False, VERBOSE=False)\n",
    "wfey_output_raw = processData(CONFIGS, EVENTRATE, EVENTPROCCPUS, SOURCECPUS, RAW=True, VERBOSE=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "789ce72d-31d8-487d-8723-01ec4fcc2f06",
   "metadata": {},
   "source": [
    "##### Remove Outliers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "e7a9a334-7d95-4391-9c4f-09fe07d7f539",
   "metadata": {},
   "outputs": [],
   "source": [
    "### HACK -- VERY TEMPORARY\n",
    "### not fixing outlier with new data yet -- it will return the same values\n",
    "def removeOutliers(DATA, THRESHHOLD_Z=2, VERBOSE=False):\n",
    "    return DATA\n",
    "\n",
    "## Removing outlier 2x -- unused sources have MAXINT as latency values and skew the z values\n",
    "wfey_no_out_first = removeOutliers(wfey_output, THRESHHOLD_Z=5, VERBOSE=False)\n",
    "wfey_no_out = removeOutliers(wfey_no_out_first, THRESHHOLD_Z=3, VERBOSE=False)\n",
    "\n",
    "wfey_no_out_raw_first = removeOutliers(wfey_output_raw, THRESHHOLD_Z=5, VERBOSE=False)\n",
    "wfey_no_out_raw = removeOutliers(wfey_no_out_raw_first, THRESHHOLD_Z=3, VERBOSE=False)\n",
    "\n",
    "#print(wfey_no_out[ ( wfey_no_out['numevents'] == 10000) & (wfey_no_out['sleeptime'] == '0.01') & (wfey_no_out['sourceCPUs'] == '10')].loc[:, ])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1b67e2d-3d53-4ae1-ad16-96b07f6b5f07",
   "metadata": {},
   "source": [
    "##### Export the Data Frames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "1fcbb3d0-b9a0-4538-ac4c-9381e1654fca",
   "metadata": {},
   "outputs": [],
   "source": [
    "wfey_output.to_pickle(HOME_DIRECTORY+'/df/'+LOGS+'_output.pkl')\n",
    "wfey_output_raw.to_pickle(HOME_DIRECTORY+'/df/'+LOGS+'_output_raw.pkl')\n",
    "\n",
    "wfey_no_out.to_pickle(HOME_DIRECTORY+'/df/'+LOGS+'_output_clean.pkl')\n",
    "wfey_no_out_raw.to_pickle(HOME_DIRECTORY+'/df/'+LOGS+'_output_clean_raw.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4212ca5-b487-43c7-88d6-7b46246e8d9f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
