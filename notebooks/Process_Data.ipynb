{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f01d331-19df-4bb4-8e33-3e5dcb1b80f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "%run SetUp.ipynb"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00741e39-f383-4d4e-95ef-4cfadd38a100",
   "metadata": {},
   "source": [
    "# Processing Logs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "003dbb37-3d39-4f1a-8720-707bcf465370",
   "metadata": {},
   "outputs": [],
   "source": [
    "def removeOutliers(DATA, THRESHHOLD_Z=2, VERBOSE=False):\n",
    "    \n",
    "    hwmon2_mean_z  = np.abs(stats.zscore(DATA['hwmon2_mean'], nan_policy='omit'))\n",
    "    hwmon2_min_z   = np.abs(stats.zscore(DATA['hwmon2_min'], nan_policy='omit'))\n",
    "    hwmon2_max_z   = np.abs(stats.zscore(DATA['hwmon2_max'], nan_policy='omit'))\n",
    "    latency_mean_z = np.abs(stats.zscore(DATA['latency_mean'], nan_policy='omit'))\n",
    "    latency_min_z  = np.abs(stats.zscore(DATA['latency_min'], nan_policy='omit'))\n",
    "    latency_max_z  = np.abs(stats.zscore(DATA['latency_max'], nan_policy='omit'))\n",
    "\n",
    "    hwmon2_mean_out = np.where(hwmon2_mean_z > THRESHHOLD_Z)[0]\n",
    "    hwmon2_min_out = np.where(hwmon2_min_z > THRESHHOLD_Z)[0]\n",
    "    hwmon2_max_out = np.where(hwmon2_max_z > THRESHHOLD_Z)[0]\n",
    "    latency_mean_out = np.where(latency_mean_z > THRESHHOLD_Z)[0]\n",
    "    latency_min_out = np.where(latency_min_z > THRESHHOLD_Z)[0]\n",
    "    latency_max_out = np.where(latency_max_z > THRESHHOLD_Z)[0]\n",
    "\n",
    "    \n",
    "    outlier_indices = np.unique(np.concat((hwmon2_mean_out, hwmon2_min_out, hwmon2_max_out, latency_mean_out, latency_min_out, latency_max_out)))\n",
    "    no_outliers = DATA.drop(outlier_indices)\n",
    "\n",
    "    if (VERBOSE):\n",
    "        print(\"Z scores:\")\n",
    "        print(\"Hwmon2 mean, min, max\")\n",
    "        print(hwmon2_mean_z, hwmon2_min_z, hwmon2_max_z)\n",
    "        print(\"Latency mean, min, max\")\n",
    "        print(latency_mean_z,latency_min_z,latency_max_z)\n",
    "        \n",
    "        print(\"Original DataFrame Shape:\", DATA.shape)\n",
    "        print(\"DataFrame Shape after Removing Outliers:\", no_outliers.shape)\n",
    "        print(\"Removed Indexes:\")\n",
    "        print(outlier_indices)\n",
    "        print(\"\\t HWMON -- mean, min, max\")\n",
    "        print(DATA.loc[hwmon2_mean_out, ['KEY', 'hwmon2_mean']])\n",
    "        print(DATA.loc[hwmon2_min_out, ['KEY', 'hwmon2_min']])\n",
    "        print(DATA.loc[hwmon2_max_out, ['KEY', 'hwmon2_max']])\n",
    "        print(\"\\t Latency -- mean, min, max\")\n",
    "        print(DATA.loc[latency_mean_out, ['KEY', 'latency_mean']])\n",
    "        print(DATA.loc[latency_min_out, ['KEY', 'latency_min']])\n",
    "        print(DATA.loc[latency_max_out, ['KEY', 'latency_max']])\n",
    "    \n",
    "    return no_outliers.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a128674-f21d-45ed-8e0b-da4245fac306",
   "metadata": {},
   "outputs": [],
   "source": [
    "arr = []\n",
    "data = []\n",
    "\n",
    "# If RAW=True this means that the entire run's hwmon data will be used, if false only the middle 68% will be used\n",
    "\n",
    "def processData(CONFIGS, EVENTRATE, EVENTPROCCPUS, SOURCESCPUS, RAW=True, VERBOSE=False):\n",
    "    for C in CONFIGS:\n",
    "        for EVENTS in EVENTRATE:\n",
    "            for EVENTCPU in EVENTPROCCPUS:\n",
    "                for SOURCECPU in SOURCECPUS:\n",
    "                    SCPUs=str(SOURCECPU).replace(\" \", \"_\")\n",
    "\n",
    "                    KEY=C+\"/\"+str(EVENTS)+\"_\"+EVENTCPU+\"_\"+SCPUs\n",
    "                    FILE=PATH_TO_LOGS+KEY+\"/\"\n",
    "                    HWMONFILE=glob.glob(FILE+'hwmon-*.out')\n",
    "\n",
    "                    # If no files found with these args -- skip\n",
    "                    if not HWMONFILE:\n",
    "                        continue\n",
    "                        \n",
    "                    ### For every run of this set of parameters concat\n",
    "                    hwmonoutput=None\n",
    "                    latencyoutput=None\n",
    "\n",
    "                    for runs in HWMONFILE:\n",
    "                        if os.path.exists(runs):\n",
    "                            if VERBOSE:\n",
    "                                print(\"processsing:\" + runs)\n",
    "                                \n",
    "                            try:\n",
    "                                df=pd.read_csv(runs, sep=' ', usecols=['hwmon2', 'hwmon3'])\n",
    "                            except:\n",
    "                                print(\"SKIPPING: \" + runs + \" --- Problem parsing hwmon numbers\")\n",
    "                                continue\n",
    "\n",
    "                            if (len(df) > OVERFLOW_NUM):\n",
    "                                print(\"SKIPPING: \" + runs  +\" --- Possible error occured during experiment\")\n",
    "                                continue\n",
    "                            \n",
    "                            hwmonoutput = pd.concat([hwmonoutput, df])\n",
    "\n",
    "                            if (list(hwmonoutput) != ['hwmon2', 'hwmon3']):\n",
    "                                ## KNOWN BUG: if no header on cvs and error with gathering HWMON it will not catch it and create table of NULL\n",
    "                                print(\"bad columns for:\", runs)\n",
    "\n",
    "                            ## --- Grabbing Latency Numbers --- ##\n",
    "                            latency_file = runs.replace(\"hwmon\", \"latency\")\n",
    "\n",
    "                            if os.path.exists(latency_file):\n",
    "                                if VERBOSE:\n",
    "                                    print(\"processsing:\" + latency_file)\n",
    "\n",
    "                                try:\n",
    "                                    latency_df = pd.read_csv(latency_file)\n",
    "                                except:\n",
    "                                    print(\"SKIPPING: \" + latency_file + \" --- Problem parsing latency numbers\")\n",
    "                                    continue\n",
    "\n",
    "                                latencyoutput = pd.concat([latencyoutput, latency_df])\n",
    "                   \n",
    "                    if (hwmonoutput is None) or (latencyoutput is None):\n",
    "                        continue\n",
    "                    \n",
    "                    ## --- Find the mean of all runs --- ##\n",
    "                    by_row_index = hwmonoutput.groupby(hwmonoutput.index)\n",
    "                    raw_result=by_row_index.mean()\n",
    "\n",
    "                    ## --- Raw Data or Middle Data --- ##\n",
    "                    results = raw_result\n",
    "                    if (not RAW):\n",
    "                        adj_index = round(len(raw_result)*(PERCENT/100))\n",
    "\n",
    "                        middle_point = round(len(raw_result)/2)\n",
    "\n",
    "                        low_index = middle_point-(math.floor(adj_index/2))\n",
    "                        high_index = middle_point + (math.floor(adj_index/2))\n",
    "\n",
    "                        results = raw_result[low_index : high_index+1]\n",
    " \n",
    "                    ## --- Find Means of Latencys --- ###\n",
    "                    ### This means that the individual data for the sources is not saved \n",
    "                    ### But I believe that's fine bc we don't care about the about the data\n",
    "                    ### at the cpu scale but the number of cpu handling the workload\n",
    "                    \n",
    "                    latency_results=latencyoutput.drop(\"ID\", axis=1)\n",
    "\n",
    "                    latency_min = latency_results.loc[:,\"Min\"].to_numpy()\n",
    "                    latency_max = latency_results.loc[:,\"Max\"].to_numpy()\n",
    "                    latency_mean = latency_results.loc[:,\"Mean\"].to_numpy()\n",
    "\n",
    "                    latency_min = stats.gmean(latency_min)\n",
    "                    latency_max = stats.gmean(latency_max)\n",
    "                    latency_mean = stats.gmean(latency_mean)\n",
    "\n",
    "                    ## --- Getting time for every power number -- #\n",
    "                    \n",
    "                    runningtime = len(results.index) * TIME_BTN_POWER\n",
    "                    \n",
    "                    time_range = np.arange(0, runningtime, TIME_BTN_POWER)\n",
    "                    \n",
    "                    ## --- Making array out of hwmon output --- ##\n",
    "                    hwmon2_pwr = results.loc[:,\"hwmon2\"].to_numpy()\n",
    "                    hwmon3_pwr = results.loc[:,\"hwmon3\"].to_numpy()\n",
    "\n",
    "                    ## --- Processing HWMON Numbers --- ## \n",
    "                    hwmon2_min = hwmon2_pwr.min()\n",
    "                    hwmon3_min = hwmon3_pwr.min()\n",
    "\n",
    "                    hwmon2_max = hwmon2_pwr.max()\n",
    "                    hwmon3_max = hwmon3_pwr.max()\n",
    "\n",
    "                    hwmon2_mean = stats.gmean(hwmon2_pwr)\n",
    "                    hwmon3_mean = stats.gmean(hwmon3_pwr)\n",
    "\n",
    "                    ## --- Adding data to list --- ##\n",
    "                    \n",
    "                    arr.append((C,EVENTS,EVENTCPU,SCPUs,hwmon2_pwr,hwmon3_pwr, hwmon2_min, hwmon2_max, hwmon2_mean, hwmon3_min, hwmon3_max, hwmon3_mean, time_range, latency_min, latency_max, latency_mean, KEY))\n",
    "\n",
    "    df = pd.DataFrame(data=arr, columns=[ \"configs\", \"eventrate\", \"eventprocCPUs\", \"sourceCPUs\", \"hwmon2\", \"hwmon3\", \"hwmon2_min\", \"hwmon2_max\", \"hwmon2_mean\", \"hwmon3_min\", \"hwmon3_max\", \"hwmon3_mean\", \"time\", \"latency_min\", \"latency_max\", \"latency_mean\", \"KEY\"])\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3aaf3751-0a3d-4978-9457-92f87e8f134f",
   "metadata": {},
   "source": [
    "### Creating Dataframes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5351f56-6543-47a4-acad-b3de35b4b741",
   "metadata": {},
   "source": [
    "##### Process the Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "584cf992-4a63-4b4b-a596-23bf4463300b",
   "metadata": {},
   "outputs": [],
   "source": [
    "wfey_output = processData(CONFIGS, EVENTRATE, EVENTPROCCPUS, SOURCECPUS, RAW=False, VERBOSE=False)\n",
    "wfey_output_raw = processData(CONFIGS, EVENTRATE, EVENTPROCCPUS, SOURCECPUS, RAW=True, VERBOSE=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "789ce72d-31d8-487d-8723-01ec4fcc2f06",
   "metadata": {},
   "source": [
    "##### Remove Outliers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7a9a334-7d95-4391-9c4f-09fe07d7f539",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Removing outlier 2x -- unused sources have MAXINT as latency values and skew the z values\n",
    "wfey_no_out_first = removeOutliers(wfey_output, THRESHHOLD_Z=5, VERBOSE=False)\n",
    "wfey_no_out = removeOutliers(wfey_no_out_first, THRESHHOLD_Z=3, VERBOSE=False)\n",
    "\n",
    "wfey_no_out_raw_first = removeOutliers(wfey_output_raw, THRESHHOLD_Z=5, VERBOSE=False)\n",
    "wfey_no_out_raw = removeOutliers(wfey_no_out_raw_first, THRESHHOLD_Z=3, VERBOSE=False)\n",
    "\n",
    "#print(wfey_no_out[ ( wfey_no_out['numevents'] == 10000) & (wfey_no_out['sleeptime'] == '0.01') & (wfey_no_out['sourceCPUs'] == '10')].loc[:, ])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1b67e2d-3d53-4ae1-ad16-96b07f6b5f07",
   "metadata": {},
   "source": [
    "##### Export the Data Frames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1fcbb3d0-b9a0-4538-ac4c-9381e1654fca",
   "metadata": {},
   "outputs": [],
   "source": [
    "wfey_output.to_pickle(HOME_DIRECTORY+'/df/'+LOGS+'_output.pkl')\n",
    "wfey_output_raw.to_pickle(HOME_DIRECTORY+'/df/'+LOGS+'_output_raw.pkl')\n",
    "\n",
    "wfey_no_out.to_pickle(HOME_DIRECTORY+'/df/'+LOGS+'_output_clean.pkl')\n",
    "wfey_no_out_raw.to_pickle(HOME_DIRECTORY+'/df/'+LOGS+'_output_clean_raw.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4212ca5-b487-43c7-88d6-7b46246e8d9f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
